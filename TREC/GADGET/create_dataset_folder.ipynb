{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('GADGET/config/config-pegasosMnist0.cfg', 'r') as fp:\n",
    "    content = fp.read().splitlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "content[8] = 'network.node.dim '\n",
    "content[10] = 'network.node.resourcepath '"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'GADGET/data/datasets/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "events = os.listdir(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['albertaFloods2013',\n",
       " 'queenslandFloods2013',\n",
       " 'Bombing_features',\n",
       " 'guatemalaEarthquake2012',\n",
       " 'fire_features',\n",
       " 'Attacks_features',\n",
       " 'nepalEarthquake2015',\n",
       " 'manilaFloods2013',\n",
       " 'Tornado_features',\n",
       " 'Shooting_features',\n",
       " 'chileEarthquake2014',\n",
       " 'philipinnesFloods2012',\n",
       " 'typhoonYolanda2013',\n",
       " 'italyEarthquakes2012',\n",
       " 'typhoonHagupit2014']"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Errno 17] File exists: 'GADGET/data/datasets/albertaFloods2013/InformationWanted'\n",
      "[Errno 17] File exists: 'GADGET/data/datasets/albertaFloods2013/Weather'\n",
      "[Errno 17] File exists: 'GADGET/data/datasets/albertaFloods2013/GoodsServices'\n",
      "[Errno 17] File exists: 'GADGET/data/datasets/albertaFloods2013/Discussion'\n",
      "[Errno 17] File exists: 'GADGET/data/datasets/albertaFloods2013/Advice'\n",
      "[Errno 17] File exists: 'GADGET/data/datasets/albertaFloods2013/CleanUp'\n",
      "[Errno 17] File exists: 'GADGET/data/datasets/albertaFloods2013/Official'\n",
      "[Errno 17] File exists: 'GADGET/data/datasets/albertaFloods2013/Factoid'\n",
      "[Errno 17] File exists: 'GADGET/data/datasets/albertaFloods2013/Irrelevant'\n",
      "[Errno 17] File exists: 'GADGET/data/datasets/albertaFloods2013/PastNews'\n",
      "[Errno 17] File exists: 'GADGET/data/datasets/albertaFloods2013/Hashtags'\n",
      "[Errno 17] File exists: 'GADGET/data/datasets/albertaFloods2013/SearchAndRescue'\n",
      "[Errno 17] File exists: 'GADGET/data/datasets/albertaFloods2013/ThirdPartyObservation'\n",
      "[Errno 17] File exists: 'GADGET/data/datasets/albertaFloods2013/MovePeople'\n",
      "[Errno 17] File exists: 'GADGET/data/datasets/albertaFloods2013/Donations'\n",
      "[Errno 17] File exists: 'GADGET/data/datasets/albertaFloods2013/EmergingThreats'\n",
      "[Errno 17] File exists: 'GADGET/data/datasets/albertaFloods2013/ServiceAvailable'\n",
      "[Errno 17] File exists: 'GADGET/data/datasets/albertaFloods2013/ContinuingNews'\n",
      "[Errno 17] File exists: 'GADGET/data/datasets/albertaFloods2013/Volunteer'\n",
      "[Errno 17] File exists: 'GADGET/data/datasets/albertaFloods2013/Unknown'\n",
      "[Errno 17] File exists: 'GADGET/data/datasets/albertaFloods2013/Sentiment'\n",
      "[Errno 17] File exists: 'GADGET/data/datasets/albertaFloods2013/SignificantEventChange'\n",
      "[Errno 17] File exists: 'GADGET/data/datasets/albertaFloods2013/FirstPartyObservation'\n",
      "[Errno 17] File exists: 'GADGET/data/datasets/albertaFloods2013/MultimediaShare'\n",
      "[Errno 17] File exists: 'GADGET/data/datasets/albertaFloods2013/KnownAlready'\n",
      "[Errno 17] File exists: 'GADGET/data/datasets/Bombing_features/InformationWanted'\n",
      "[Errno 17] File exists: 'GADGET/data/datasets/Bombing_features/GoodsServices'\n",
      "[Errno 17] File exists: 'GADGET/data/datasets/Bombing_features/Discussion'\n",
      "[Errno 17] File exists: 'GADGET/data/datasets/Bombing_features/Advice'\n",
      "[Errno 17] File exists: 'GADGET/data/datasets/Bombing_features/Official'\n",
      "[Errno 17] File exists: 'GADGET/data/datasets/Bombing_features/Factoid'\n",
      "[Errno 17] File exists: 'GADGET/data/datasets/Bombing_features/Irrelevant'\n",
      "[Errno 17] File exists: 'GADGET/data/datasets/Bombing_features/PastNews'\n",
      "[Errno 17] File exists: 'GADGET/data/datasets/Bombing_features/Hashtags'\n",
      "[Errno 17] File exists: 'GADGET/data/datasets/Bombing_features/ThirdPartyObservation'\n",
      "[Errno 17] File exists: 'GADGET/data/datasets/Bombing_features/Donations'\n",
      "[Errno 17] File exists: 'GADGET/data/datasets/Bombing_features/EmergingThreats'\n",
      "[Errno 17] File exists: 'GADGET/data/datasets/Bombing_features/ServiceAvailable'\n",
      "[Errno 17] File exists: 'GADGET/data/datasets/Bombing_features/ContinuingNews'\n",
      "[Errno 17] File exists: 'GADGET/data/datasets/Bombing_features/Volunteer'\n",
      "[Errno 17] File exists: 'GADGET/data/datasets/Bombing_features/Sentiment'\n",
      "[Errno 17] File exists: 'GADGET/data/datasets/Bombing_features/SignificantEventChange'\n",
      "[Errno 17] File exists: 'GADGET/data/datasets/Bombing_features/FirstPartyObservation'\n",
      "[Errno 17] File exists: 'GADGET/data/datasets/Bombing_features/MultimediaShare'\n",
      "[Errno 17] File exists: 'GADGET/data/datasets/Bombing_features/KnownAlready'\n",
      "[Errno 17] File exists: 'GADGET/data/datasets/fire_features/InformationWanted'\n",
      "[Errno 17] File exists: 'GADGET/data/datasets/fire_features/Weather'\n",
      "[Errno 17] File exists: 'GADGET/data/datasets/fire_features/Discussion'\n",
      "[Errno 17] File exists: 'GADGET/data/datasets/fire_features/Advice'\n",
      "[Errno 17] File exists: 'GADGET/data/datasets/fire_features/Official'\n",
      "[Errno 17] File exists: 'GADGET/data/datasets/fire_features/Factoid'\n",
      "[Errno 17] File exists: 'GADGET/data/datasets/fire_features/Irrelevant'\n",
      "[Errno 17] File exists: 'GADGET/data/datasets/fire_features/PastNews'\n",
      "[Errno 17] File exists: 'GADGET/data/datasets/fire_features/ThirdPartyObservation'\n",
      "[Errno 17] File exists: 'GADGET/data/datasets/fire_features/MovePeople'\n",
      "[Errno 17] File exists: 'GADGET/data/datasets/fire_features/Donations'\n",
      "[Errno 17] File exists: 'GADGET/data/datasets/fire_features/EmergingThreats'\n",
      "[Errno 17] File exists: 'GADGET/data/datasets/fire_features/ServiceAvailable'\n",
      "[Errno 17] File exists: 'GADGET/data/datasets/fire_features/ContinuingNews'\n",
      "[Errno 17] File exists: 'GADGET/data/datasets/fire_features/Volunteer'\n",
      "[Errno 17] File exists: 'GADGET/data/datasets/fire_features/Sentiment'\n",
      "[Errno 17] File exists: 'GADGET/data/datasets/fire_features/SignificantEventChange'\n",
      "[Errno 17] File exists: 'GADGET/data/datasets/fire_features/FirstPartyObservation'\n",
      "[Errno 17] File exists: 'GADGET/data/datasets/fire_features/MultimediaShare'\n",
      "[Errno 17] File exists: 'GADGET/data/datasets/fire_features/KnownAlready'\n",
      "[Errno 17] File exists: 'GADGET/data/datasets/Attacks_features/Discussion'\n",
      "[Errno 17] File exists: 'GADGET/data/datasets/Attacks_features/Advice'\n",
      "[Errno 17] File exists: 'GADGET/data/datasets/Attacks_features/Official'\n",
      "[Errno 17] File exists: 'GADGET/data/datasets/Attacks_features/Factoid'\n",
      "[Errno 17] File exists: 'GADGET/data/datasets/Attacks_features/Irrelevant'\n",
      "[Errno 17] File exists: 'GADGET/data/datasets/Attacks_features/Hashtags'\n",
      "[Errno 17] File exists: 'GADGET/data/datasets/Attacks_features/SearchAndRescue'\n",
      "[Errno 17] File exists: 'GADGET/data/datasets/Attacks_features/ThirdPartyObservation'\n",
      "[Errno 17] File exists: 'GADGET/data/datasets/Attacks_features/EmergingThreats'\n",
      "[Errno 17] File exists: 'GADGET/data/datasets/Attacks_features/ServiceAvailable'\n",
      "[Errno 17] File exists: 'GADGET/data/datasets/Attacks_features/ContinuingNews'\n",
      "[Errno 17] File exists: 'GADGET/data/datasets/Attacks_features/Unknown'\n",
      "[Errno 17] File exists: 'GADGET/data/datasets/Attacks_features/Sentiment'\n",
      "[Errno 17] File exists: 'GADGET/data/datasets/Attacks_features/SignificantEventChange'\n",
      "[Errno 17] File exists: 'GADGET/data/datasets/Attacks_features/FirstPartyObservation'\n",
      "[Errno 17] File exists: 'GADGET/data/datasets/Attacks_features/MultimediaShare'\n",
      "[Errno 17] File exists: 'GADGET/data/datasets/Attacks_features/KnownAlready'\n",
      "[Errno 17] File exists: 'GADGET/data/datasets/chileEarthquake2014/InformationWanted'\n",
      "[Errno 17] File exists: 'GADGET/data/datasets/chileEarthquake2014/Weather'\n",
      "[Errno 17] File exists: 'GADGET/data/datasets/chileEarthquake2014/GoodsServices'\n",
      "[Errno 17] File exists: 'GADGET/data/datasets/chileEarthquake2014/Discussion'\n",
      "[Errno 17] File exists: 'GADGET/data/datasets/chileEarthquake2014/Advice'\n",
      "[Errno 17] File exists: 'GADGET/data/datasets/chileEarthquake2014/CleanUp'\n",
      "[Errno 17] File exists: 'GADGET/data/datasets/chileEarthquake2014/Official'\n",
      "[Errno 17] File exists: 'GADGET/data/datasets/chileEarthquake2014/Factoid'\n",
      "[Errno 17] File exists: 'GADGET/data/datasets/chileEarthquake2014/Irrelevant'\n",
      "[Errno 17] File exists: 'GADGET/data/datasets/chileEarthquake2014/PastNews'\n",
      "[Errno 17] File exists: 'GADGET/data/datasets/chileEarthquake2014/Hashtags'\n",
      "[Errno 17] File exists: 'GADGET/data/datasets/chileEarthquake2014/SearchAndRescue'\n",
      "[Errno 17] File exists: 'GADGET/data/datasets/chileEarthquake2014/ThirdPartyObservation'\n",
      "[Errno 17] File exists: 'GADGET/data/datasets/chileEarthquake2014/MovePeople'\n",
      "[Errno 17] File exists: 'GADGET/data/datasets/chileEarthquake2014/Donations'\n",
      "[Errno 17] File exists: 'GADGET/data/datasets/chileEarthquake2014/EmergingThreats'\n",
      "[Errno 17] File exists: 'GADGET/data/datasets/chileEarthquake2014/ServiceAvailable'\n",
      "[Errno 17] File exists: 'GADGET/data/datasets/chileEarthquake2014/ContinuingNews'\n",
      "[Errno 17] File exists: 'GADGET/data/datasets/chileEarthquake2014/Volunteer'\n",
      "[Errno 17] File exists: 'GADGET/data/datasets/chileEarthquake2014/Unknown'\n",
      "[Errno 17] File exists: 'GADGET/data/datasets/chileEarthquake2014/Sentiment'\n",
      "[Errno 17] File exists: 'GADGET/data/datasets/chileEarthquake2014/SignificantEventChange'\n",
      "[Errno 17] File exists: 'GADGET/data/datasets/chileEarthquake2014/FirstPartyObservation'\n",
      "[Errno 17] File exists: 'GADGET/data/datasets/chileEarthquake2014/MultimediaShare'\n",
      "[Errno 17] File exists: 'GADGET/data/datasets/chileEarthquake2014/KnownAlready'\n"
     ]
    }
   ],
   "source": [
    "commands = []\n",
    "for each in events:\n",
    "    classes = os.listdir(path+each)\n",
    "    done = []\n",
    "    for eachclass in classes:\n",
    "        draftcontent = content.copy()\n",
    "        splits = eachclass.split('_')\n",
    "        if splits[0] in done: continue\n",
    "        try:\n",
    "            os.mkdir(path+each+'/'+splits[0])\n",
    "        except Exception as ex:\n",
    "            print(ex)\n",
    "            continue\n",
    "        commands.append(\"mv \"+each+\"/\"+splits[0]+\"*.txt\"+\" \"+each+\"/\"+splits[0]+\"/\")\n",
    "        draftcontent[8] +=  splits[-1][:4]\n",
    "        draftcontent[10] += \"/home/harsha/TREC_Proj/GADGET/GADGET/data/datasets/\"+each+\"/\"+splits[0] \n",
    "        with open(path+each+'/'+splits[0]+'/config-pegasos.cfg', 'w') as fp:\n",
    "            for eachcontent in draftcontent:\n",
    "                fp.write(\"%s\\n\"% (eachcontent))\n",
    "        done.append(splits[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('GADGET/data/datasets/commands.sh', 'w') as fp:\n",
    "    for comm in commands:\n",
    "        fp.write(\"%s\\n\"% (comm))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Only Config file change"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "for each in events:\n",
    "    classes = os.listdir(path+each)\n",
    "    done = []\n",
    "    for eachclass in classes:\n",
    "        draftcontent = content.copy()\n",
    "        cf = os.listdir(path+each+'/'+eachclass)\n",
    "        eclass = [j for j in cf if '.txt' in j][0]\n",
    "        splits = eclass.split('_')\n",
    "        if splits[0] in done: continue\n",
    "        draftcontent[8] +=  str(int(splits[-1][:2]) -1)+\"99\"\n",
    "        draftcontent[10] += \"/home/harsha/TREC_Proj/GADGET/GADGET/data/datasets/\"+each+\"/\"+splits[0] \n",
    "        with open(path+each+'/'+splits[0]+'/config-pegasos.cfg', 'w') as fp:\n",
    "            for eachcontent in draftcontent:\n",
    "                fp.write(\"%s\\n\"% (eachcontent))\n",
    "        done.append(splits[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('split_data.sh', 'w') as fp:\n",
    "    fp.write(\"%s\\n\\n\" %(\"%!/bin/bash\"))\n",
    "    for each in events:\n",
    "        classes = os.listdir(path+each)\n",
    "        for eachclass in classes:\n",
    "            cf = os.listdir(path+each+'/'+eachclass)\n",
    "            trfile = cf[0] if 'train' in cf[0] else cf[1] if 'train' in cf[1] else cf[2]\n",
    "            tstfile = cf[0] if 'test' in cf[0] else cf[1] if 'test' in cf[1] else cf[2]\n",
    "            val = \"python split_data.py --datafolder ../data/datasets/\"+each+\" --dataset \"+eachclass+\" --trainfile \"+trfile+\" --testfile \"+tstfile+\" --splits 10\"\n",
    "            fp.write(\"%s\\n\"%(val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### make each file for datapoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('one_dp.sh', 'w') as fp:\n",
    "    fp.write(\"%s\\n\\n\" %(\"%!/bin/bash\"))\n",
    "    for each in events:\n",
    "        classes = os.listdir(path+each)\n",
    "        for eachclass in classes:\n",
    "            for i in range(10):\n",
    "                val = \"python one_dp_per_file.py --datafolder ../data/datasets/\"+each+\" --dataset \"+eachclass+\" --file t_\"+str(i)+\".dat\"\n",
    "                fp.write(\"%s\\n\"%(val))\n",
    "                val = \"python one_dp_per_file.py --datafolder ../data/datasets/\"+each+\" --dataset \"+eachclass+\" --file tst_\"+str(i)+\".dat\"\n",
    "                fp.write(\"%s\\n\"%(val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare running command"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "npath = 'data/datasets/'\n",
    "with open('bash_train.sh', 'w') as fp:\n",
    "    fp.write(\"%s\\n\\n\" %(\"%!/bin/bash\"))\n",
    "    for each in events:\n",
    "        classes = os.listdir(path+each)\n",
    "        for eachclass in classes:\n",
    "            yespath = npath+each+'/'+eachclass+'/'\n",
    "            fp.write(\"%s\\n\" %('java -jar gadget_svm.jar '+yespath+'config-pegasos.cfg '+yespath+'output.txt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('GADGET/data/datasets/',\n",
       " ['albertaFloods2013',\n",
       "  'queenslandFloods2013',\n",
       "  'Bombing_features',\n",
       "  'guatemalaEarthquake2012',\n",
       "  'fire_features',\n",
       "  'Attacks_features',\n",
       "  'nepalEarthquake2015',\n",
       "  'manilaFloods2013',\n",
       "  'Tornado_features',\n",
       "  'Shooting_features',\n",
       "  'chileEarthquake2014',\n",
       "  'philipinnesFloods2012',\n",
       "  'typhoonYolanda2013',\n",
       "  'italyEarthquakes2012',\n",
       "  'typhoonHagupit2014'])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path, events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "commands = []\n",
    "for each in events:\n",
    "    classes = os.listdir(path+each)\n",
    "    for eachclass in classes:\n",
    "        commands.append(\"rm \"+path+each+'/'+eachclass+'/*.dat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('remove_datt.sh','w') as fp:\n",
    "    fp.write(\"%s\\n\" %(\"#!/bin/bash\"))\n",
    "    for com in commands:\n",
    "        fp.write(\"%s\\n\"%(com))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
