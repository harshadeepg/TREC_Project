{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import collections\n",
    "import itertools\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import string\n",
    "import re\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "allevents = os.listdir('Features')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading Event: Shooting_features.csv\n",
      "**********************************************************************\n",
      "Finished Class: flSchoolShooting2018\n",
      "--------------------------------------------------------------------\n",
      "Reading Event: Attacks_features.csv\n",
      "**********************************************************************\n",
      "Finished Class: parisAttacks2015\n",
      "--------------------------------------------------------------------\n",
      "Reading Event: fire_features.csv\n",
      "**********************************************************************\n",
      "Finished Class: australiaBushfire2013\n",
      "--------------------------------------------------------------------\n",
      "Reading Event: Floods_features.csv\n",
      "**********************************************************************\n",
      "Finished Class: philipinnesFloods2012\n",
      "--------------------------------------------------------------------\n",
      "Finished Class: albertaFloods2013\n",
      "--------------------------------------------------------------------\n",
      "Finished Class: queenslandFloods2013\n",
      "--------------------------------------------------------------------\n",
      "Finished Class: manilaFloods2013\n",
      "--------------------------------------------------------------------\n",
      "Reading Event: Bombing_features.csv\n",
      "**********************************************************************\n",
      "Finished Class: bostonBombings2013\n",
      "--------------------------------------------------------------------\n",
      "Reading Event: Earthquake_features.csv\n",
      "**********************************************************************\n",
      "Finished Class: italyEarthquakes2012\n",
      "--------------------------------------------------------------------\n",
      "Finished Class: nepalEarthquake2015\n",
      "--------------------------------------------------------------------\n",
      "Finished Class: chileEarthquake2014\n",
      "--------------------------------------------------------------------\n",
      "Finished Class: guatemalaEarthquake2012\n",
      "--------------------------------------------------------------------\n",
      "Reading Event: typhoon_features.csv\n",
      "**********************************************************************\n",
      "Finished Class: typhoonHagupit2014\n",
      "--------------------------------------------------------------------\n",
      "Finished Class: typhoonYolanda2013\n",
      "--------------------------------------------------------------------\n",
      "Reading Event: Tornado_features.csv\n",
      "**********************************************************************\n",
      "Finished Class: joplinTornado2011\n",
      "--------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "for event in allevents:\n",
    "    print(\"Reading Event:\", event)\n",
    "    print(\"**********************************************************************\")\n",
    "    df = pd.read_csv('Features/'+event).drop('Unnamed: 0', axis=1)\n",
    "    subtopics = list(collections.Counter(df[\"topics\"].tolist()))\n",
    "    for eachsubtopic in subtopics:\n",
    "        newdf = df[df[\"topics\"] == eachsubtopic]\n",
    "        allabels = newdf.columns[4:-1]\n",
    "        dataframe = pd.DataFrame()\n",
    "        dataframe = dataframe.append([['Class Name', 'Negative(0) class', 'Positive(1) class']])\n",
    "        for each in allabels:\n",
    "            dataframe = dataframe.append([[each,len(newdf[newdf[each] == 0]), len(newdf[newdf[each] == 1])]])\n",
    "        dataframe.to_csv(\"Stats/\"+eachsubtopic+'.csv', index = False, header = False)    \n",
    "        print(\"Finished Class:\", eachsubtopic)\n",
    "        print(\"--------------------------------------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading Event: Shooting_features.csv\n",
      "**********************************************************************\n",
      "Finished Class: flSchoolShooting2018\n",
      "--------------------------------------------------------------------\n",
      "Reading Event: Attacks_features.csv\n",
      "**********************************************************************\n",
      "Finished Class: parisAttacks2015\n",
      "--------------------------------------------------------------------\n",
      "Reading Event: fire_features.csv\n",
      "**********************************************************************\n",
      "Finished Class: australiaBushfire2013\n",
      "--------------------------------------------------------------------\n",
      "Reading Event: Floods_features.csv\n",
      "**********************************************************************\n",
      "Finished Class: philipinnesFloods2012\n",
      "--------------------------------------------------------------------\n",
      "Finished Class: albertaFloods2013\n",
      "--------------------------------------------------------------------\n",
      "Finished Class: queenslandFloods2013\n",
      "--------------------------------------------------------------------\n",
      "Finished Class: manilaFloods2013\n",
      "--------------------------------------------------------------------\n",
      "Reading Event: Bombing_features.csv\n",
      "**********************************************************************\n",
      "Finished Class: bostonBombings2013\n",
      "--------------------------------------------------------------------\n",
      "Reading Event: Earthquake_features.csv\n",
      "**********************************************************************\n",
      "Finished Class: italyEarthquakes2012\n",
      "--------------------------------------------------------------------\n",
      "Finished Class: nepalEarthquake2015\n",
      "--------------------------------------------------------------------\n",
      "Finished Class: chileEarthquake2014\n",
      "--------------------------------------------------------------------\n",
      "Finished Class: guatemalaEarthquake2012\n",
      "--------------------------------------------------------------------\n",
      "Reading Event: typhoon_features.csv\n",
      "**********************************************************************\n",
      "Finished Class: typhoonHagupit2014\n",
      "--------------------------------------------------------------------\n",
      "Finished Class: typhoonYolanda2013\n",
      "--------------------------------------------------------------------\n",
      "Reading Event: Tornado_features.csv\n",
      "**********************************************************************\n",
      "Finished Class: joplinTornado2011\n",
      "--------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "for event in allevents:\n",
    "    print(\"Reading Event:\", event)\n",
    "    print(\"**********************************************************************\")\n",
    "    df = pd.read_csv('Features/'+event).drop('Unnamed: 0', axis=1)\n",
    "    subtopics = list(collections.Counter(df[\"topics\"].tolist()))\n",
    "    for eachsubtopic in subtopics:\n",
    "        newdf = df[df[\"topics\"] == eachsubtopic]\n",
    "        allabels = newdf.columns[4:-1]\n",
    "        with open(\"Stats/\"+eachsubtopic+'.txt','w') as fp:\n",
    "            fp.write(\"%s\\t%s\\t%s\\n\"%('Class Name', 'Negative(0) class', 'Positive(1) class'))\n",
    "            for each in allabels:\n",
    "                fp.write(\"%s\\t%s\\t%s\\n\"%(each,len(newdf[newdf[each] == 0]), len(newdf[newdf[each] == 1])))\n",
    "        print(\"Finished Class:\", eachsubtopic)\n",
    "        print(\"--------------------------------------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading Event: Shooting_features.csv\n",
      "**********************************************************************\n",
      "Finished Class: flSchoolShooting2018\n",
      "--------------------------------------------------------------------\n",
      "Reading Event: Attacks_features.csv\n",
      "**********************************************************************\n",
      "Finished Class: parisAttacks2015\n",
      "--------------------------------------------------------------------\n",
      "Reading Event: fire_features.csv\n",
      "**********************************************************************\n",
      "Finished Class: australiaBushfire2013\n",
      "--------------------------------------------------------------------\n",
      "Reading Event: Floods_features.csv\n",
      "**********************************************************************\n",
      "Finished Class: philipinnesFloods2012\n",
      "--------------------------------------------------------------------\n",
      "Finished Class: albertaFloods2013\n",
      "--------------------------------------------------------------------\n",
      "Finished Class: queenslandFloods2013\n",
      "--------------------------------------------------------------------\n",
      "Finished Class: manilaFloods2013\n",
      "--------------------------------------------------------------------\n",
      "Reading Event: Bombing_features.csv\n",
      "**********************************************************************\n",
      "Finished Class: bostonBombings2013\n",
      "--------------------------------------------------------------------\n",
      "Reading Event: Earthquake_features.csv\n",
      "**********************************************************************\n",
      "Finished Class: italyEarthquakes2012\n",
      "--------------------------------------------------------------------\n",
      "Finished Class: nepalEarthquake2015\n",
      "--------------------------------------------------------------------\n",
      "Finished Class: chileEarthquake2014\n",
      "--------------------------------------------------------------------\n",
      "Finished Class: guatemalaEarthquake2012\n",
      "--------------------------------------------------------------------\n",
      "Reading Event: typhoon_features.csv\n",
      "**********************************************************************\n",
      "Finished Class: typhoonHagupit2014\n",
      "--------------------------------------------------------------------\n",
      "Finished Class: typhoonYolanda2013\n",
      "--------------------------------------------------------------------\n",
      "Reading Event: Tornado_features.csv\n",
      "**********************************************************************\n",
      "Finished Class: joplinTornado2011\n",
      "--------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "for event in allevents:\n",
    "    print(\"Reading Event:\", event)\n",
    "    print(\"**********************************************************************\")\n",
    "    df = pd.read_csv('Features/'+event).drop('Unnamed: 0', axis=1)\n",
    "    subtopics = list(collections.Counter(df[\"topics\"].tolist()))\n",
    "    for eachsubtopic in subtopics:\n",
    "        newdf = df[df[\"topics\"] == eachsubtopic]\n",
    "        allabels = newdf.columns[4:-1]\n",
    "        with open(\"Stats/\"+eachsubtopic+'.txt','w') as fp:\n",
    "            fp.write(\"%s\\t\\t\\t\\t\\t%s\\n\\n\" %(\"LabeName\", \"Class distribution\"))\n",
    "            fp.write(\"%s\\n\"%\"---------------------------------------------------------------\")\n",
    "            fp.write(\"%s\\n\\n\" %\"Class info: 0 - negative class, 1 - positive class\")\n",
    "            fp.write(\"%s\\n\"%\"---------------------------------------------------------------\")\n",
    "            for each in allabels:\n",
    "                fp.write(\"%s\\t\\t\\t\\t\\t%s\\n\\n\" % (each,dict(collections.Counter(newdf[each].tolist()))))\n",
    "            \n",
    "        print(\"Finished Class:\", eachsubtopic)\n",
    "        print(\"--------------------------------------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
